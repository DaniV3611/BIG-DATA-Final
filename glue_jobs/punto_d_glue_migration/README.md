# Punto d) Migraci√≥n a Glue Jobs y Workflows

Esta implementaci√≥n migra los puntos **a)**, **b)** y **c)** de Lambdas a **AWS Glue Jobs** articulados en un **workflow**.

## üìã Contenido

### Jobs Implementados

1. **`extractor_job.py`** - Migraci√≥n del punto a)

   - Extracci√≥n web de El Tiempo y El Espectador
   - Almacenamiento en S3 como HTML crudo
   - Reemplaza la funcionalidad del Lambda extractor

2. **`processor_job.py`** - Migraci√≥n del punto b)

   - Procesamiento HTML con BeautifulSoup
   - Extracci√≥n de datos estructurados (categor√≠a, titular, enlace)
   - Almacenamiento particionado en S3 como CSV
   - Reemplaza la funcionalidad del Lambda processor

3. **`crawler_job.py`** - Migraci√≥n del punto c)
   - Ejecuci√≥n de crawler Glue usando boto3
   - Actualizaci√≥n de particiones en cat√°logo
   - Habilitaci√≥n de consultas en AWS Athena
   - Reemplaza la funcionalidad del Lambda crawler

## üîÑ Flujo de Trabajo

```mermaid
graph LR
    A[Extractor Job] --> B[Processor Job]
    B --> C[Crawler Job]

    A --> D[S3 Raw HTML]
    B --> E[S3 Partitioned CSV]
    C --> F[Glue Data Catalog]
    F --> G[AWS Athena]
```

## üìä Esquema de Datos

### Entrada (HTML crudo)

```
s3://bucket/headlines/raw/contenido-yyyy-mm-dd.html
```

### Salida (CSV estructurado)

```
s3://bucket/headlines/final/periodico=xxx/year=xxx/month=xxx/day=xxx/
```

**Campos extra√≠dos:**

- `fecha`: Fecha de la noticia
- `categoria`: Categor√≠a/secci√≥n del art√≠culo
- `titular`: T√≠tulo de la noticia
- `enlace`: URL completa del art√≠culo
- `periodico`: Nombre del peri√≥dico (eltiempo/elespectador)

## üöÄ Deployment

Estos jobs se despliegan autom√°ticamente como parte del workflow principal:

```bash
cd glue_jobs/
python deploy.py YOUR_BUCKET_NAME YOUR_IAM_ROLE_ARN us-east-1
```

## ‚öôÔ∏è Configuraci√≥n de Jobs

### Recursos

- **Worker Type**: G.1X (4 vCPU, 16 GB RAM)
- **Number of Workers**: 2
- **Timeout**: 60 minutos
- **Glue Version**: 3.0

### Par√°metros

- `--S3_BUCKET`: Bucket de S3 para almacenamiento
- `--S3_PREFIX`: Prefijo para archivos de entrada
- `--S3_OUTPUT_PREFIX`: Prefijo para archivos de salida
- `--DATABASE_NAME`: Base de datos en Glue Catalog
- `--CRAWLER_NAME`: Nombre del crawler
- `--IAM_ROLE_ARN`: Rol IAM para el crawler

## üìà Ventajas sobre Lambdas

### Escalabilidad

- ‚úÖ Procesamiento distribuido con Spark
- ‚úÖ Manejo de vol√∫menes grandes de datos
- ‚úÖ Auto-scaling autom√°tico de workers

### Durabilidad

- ‚úÖ Timeout extendido (15 min ‚Üí 60 min)
- ‚úÖ Reintentos autom√°ticos
- ‚úÖ Job bookmarks para continuidad

### Monitoreo

- ‚úÖ CloudWatch m√©tricas detalladas
- ‚úÖ Logs estructurados
- ‚úÖ Integraci√≥n con workflow de Glue

### Costo

- ‚úÖ Pago por uso (sin tiempo idle)
- ‚úÖ Mejor para procesamiento batch
- ‚úÖ Optimizaci√≥n autom√°tica de recursos

## üß™ Testing Individual

Para probar jobs individualmente:

```bash
# Extractor
aws glue start-job-run --job-name news-extractor-job

# Processor
aws glue start-job-run --job-name news-processor-job

# Crawler
aws glue start-job-run --job-name news-crawler-job
```

## üìã Criterios de Migraci√≥n Exitosa

- [x] **Funcionalidad equivalente** - Misma extracci√≥n y procesamiento
- [x] **Mejores recursos** - Procesamiento distribuido
- [x] **Workflow autom√°tico** - Ejecuci√≥n secuencial
- [x] **Triggers condicionales** - Basados en √©xito/fallo
- [x] **Monitoreo mejorado** - CloudWatch integrado
- [x] **Escalabilidad** - Manejo de datos grandes

## üîó Referencias

- [AWS Glue Jobs](https://docs.aws.amazon.com/glue/latest/dg/author-job.html)
- [AWS Glue Workflows](https://docs.aws.amazon.com/glue/latest/dg/workflows_overview.html)
- [Migraci√≥n Lambda a Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python.html)
